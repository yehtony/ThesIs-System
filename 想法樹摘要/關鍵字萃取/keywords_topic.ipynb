{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callGpt(\n",
    "        userText: str,\n",
    "        messages: List[Any],\n",
    "        temperature: float = 0.7,\n",
    "        max_tokens: int = 500\n",
    "    ) -> str:\n",
    "    url: str = f\"https://model.hsueh.tw/callapi/chatGPT?temperature={temperature}&max_tokens={max_tokens}&top_p=0.95&frequency_penalty=0&presence_penalty=0&stop=\"\"&past_messages=3&purpose=none\"\n",
    "    payload = json.dumps(messages)\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    try:\n",
    "        return str(response.json()['choices'][0]['message']['content'])\n",
    "    except:\n",
    "        return \"ERROR:\"+str(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callGPT_keywords_extract(userText: str) -> str:\n",
    "        return callGpt(userText, [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"\n",
    "                    你是一名台灣國小自然科學領域的老師，你發起了國小自然科學探究活動的題目，你現在必須提取出和探究題目有關以及學生在探究過程中需要聚焦的10個重要的關鍵字，請以台灣國小自然科學課綱會出現的詞彙為主，除關鍵字之外請不要回覆其他訊息。注意，請以'、'區隔，不要出現其他格式的訊息。\n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": userText}\n",
    "        ],0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "太陽能、光電效應、太陽能板、能量轉換、環保、可再生能源、發電原理、電能儲存、太陽能利用、綠色能源。\n"
     ]
    }
   ],
   "source": [
    "activity_topic = \"\"\"太陽光為什麼可以發電？\"\"\"\n",
    "keywords_topic = callGPT_keywords_extract(activity_topic)\n",
    "print(keywords_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似度分数： 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 两组关键字数据\n",
    "keywords1 = \"太陽能、光電效應、太陽能板、能量轉換、環保、可再生能源、發電原理、電能儲存、太陽能利用、綠色能源\"\n",
    "keywords2 = \"宇宙、太空梭、衛星、黑洞、地心引力、蟲洞、暗物質、太陽\"\n",
    "\n",
    "# 合并两组关键字数据为文档列表\n",
    "documents = [keywords1, keywords2]\n",
    "\n",
    "# 创建TF-IDF向量化器\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 转换文档为TF-IDF向量\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# 计算余弦相似度\n",
    "similarities = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "# 打印相似度分数\n",
    "print(\"相似度分数：\", similarities[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似度矩阵：\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.08464773 0.08464773 0.08464773 0.08464773 0.         0.08464773\n",
      "  0.06022756 0.06022756 0.         0.06022756 0.08464773 0.06022756\n",
      "  0.08464773 0.         0.08464773 0.06022756 0.08464773 0.08464773\n",
      "  0.16929547 0.         0.08464773 0.08464773 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.06022756 0.06022756 0.06022756 0.06022756 0.         0.06022756\n",
      "  0.0428524  0.0428524  0.         0.0428524  0.06022756 0.0428524\n",
      "  0.06022756 0.         0.06022756 0.0428524  0.06022756 0.06022756\n",
      "  0.12045512 0.         0.06022756 0.06022756 0.        ]\n",
      " [0.06022756 0.06022756 0.06022756 0.06022756 0.         0.06022756\n",
      "  0.0428524  0.0428524  0.         0.0428524  0.06022756 0.0428524\n",
      "  0.06022756 0.         0.06022756 0.0428524  0.06022756 0.06022756\n",
      "  0.12045512 0.         0.06022756 0.06022756 0.        ]\n",
      " [0.08464773 0.08464773 0.08464773 0.08464773 0.         0.08464773\n",
      "  0.06022756 0.06022756 0.         0.06022756 0.08464773 0.06022756\n",
      "  0.08464773 0.         0.08464773 0.06022756 0.08464773 0.08464773\n",
      "  0.16929547 0.         0.08464773 0.08464773 0.        ]\n",
      " [0.06022756 0.06022756 0.06022756 0.06022756 0.         0.06022756\n",
      "  0.0428524  0.0428524  0.         0.0428524  0.06022756 0.0428524\n",
      "  0.06022756 0.         0.06022756 0.0428524  0.06022756 0.06022756\n",
      "  0.12045512 0.         0.06022756 0.06022756 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.06022756 0.06022756 0.06022756 0.06022756 0.         0.06022756\n",
      "  0.0428524  0.0428524  0.         0.0428524  0.06022756 0.0428524\n",
      "  0.06022756 0.         0.06022756 0.0428524  0.06022756 0.06022756\n",
      "  0.12045512 0.         0.06022756 0.06022756 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.08464773 0.08464773 0.08464773 0.08464773 0.         0.08464773\n",
      "  0.06022756 0.06022756 0.         0.06022756 0.08464773 0.06022756\n",
      "  0.08464773 0.         0.08464773 0.06022756 0.08464773 0.08464773\n",
      "  0.16929547 0.         0.08464773 0.08464773 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.06022756 0.06022756 0.06022756 0.06022756 0.         0.06022756\n",
      "  0.0428524  0.0428524  0.         0.0428524  0.06022756 0.0428524\n",
      "  0.06022756 0.         0.06022756 0.0428524  0.06022756 0.06022756\n",
      "  0.12045512 0.         0.06022756 0.06022756 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.08464773 0.08464773 0.08464773 0.08464773 0.         0.08464773\n",
      "  0.06022756 0.06022756 0.         0.06022756 0.08464773 0.06022756\n",
      "  0.08464773 0.         0.08464773 0.06022756 0.08464773 0.08464773\n",
      "  0.16929547 0.         0.08464773 0.08464773 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.08464773 0.08464773 0.08464773 0.08464773 0.         0.08464773\n",
      "  0.06022756 0.06022756 0.         0.06022756 0.08464773 0.06022756\n",
      "  0.08464773 0.         0.08464773 0.06022756 0.08464773 0.08464773\n",
      "  0.16929547 0.         0.08464773 0.08464773 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 两组关键字数据\n",
    "keywords1 = \"太陽能、光電效應、太陽能板、能量轉換、環保\"\n",
    "keywords2 = \"太陽能、太陽能板、發電、光能、轉換效率\"\n",
    "\n",
    "# 将关键字数据分割成单词列表\n",
    "keywords1_list = keywords1.split('、')\n",
    "keywords2_list = keywords2.split('、')\n",
    "\n",
    "# 创建TF-IDF向量化器\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([keywords1, keywords2])\n",
    "\n",
    "# 计算余弦相似度矩阵\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# 提取keywords1和keywords2之间的相似度\n",
    "similarity_matrix = cosine_sim_matrix[0, 1:]\n",
    "\n",
    "# 创建一个相似度矩阵\n",
    "similarity_matrix = np.reshape(similarity_matrix, (1, -1))\n",
    "\n",
    "# 创建一个矩阵，其中包含keyword1中的每个词与keyword2中的每个词之间的相似度\n",
    "similarity_matrix = np.outer(tfidf_matrix.toarray()[0], tfidf_matrix.toarray()[1])\n",
    "\n",
    "# 打印相似度矩阵\n",
    "print(\"相似度矩阵：\")\n",
    "print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似度矩阵：\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "\n",
    "# # 两组关键字数据\n",
    "# keywords1 = \"太陽能、光電效應、太陽能板、能量轉換、環保\"\n",
    "# keywords2 = \"太陽能、太陽能板、發電、光能、轉換效率\"\n",
    "\n",
    "# # 将关键字数据分割成单词列表\n",
    "# keywords1_list = keywords1.split('、')\n",
    "# keywords2_list = keywords2.split('、')\n",
    "\n",
    "# # 创建一个5x5的矩阵来存储相似度值\n",
    "# similarity_matrix = np.zeros((5, 5))\n",
    "\n",
    "# # 创建TF-IDF向量化器\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# # 计算每个词在keywords2与keywords1之间的相似度\n",
    "# for i in range(5):\n",
    "#     for j in range(5):\n",
    "#         # 转换为TF-IDF向量\n",
    "#         tfidf_matrix = tfidf_vectorizer.fit_transform([keywords1_list[j], keywords2_list[i]])\n",
    "#         # 提取keywords1与keywords2之间的相似度\n",
    "#         similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "#         # 存储相似度值到矩阵\n",
    "#         similarity_matrix[i, j] = similarity\n",
    "\n",
    "# # 打印相似度矩阵\n",
    "# print(\"相似度矩阵：\")\n",
    "# print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.16.0-cp310-cp310-win_amd64.whl (1.3 MB)\n",
      "Requirement already satisfied: nltk in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: scipy in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.10.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (22.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (2022.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.11.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from nltk->sentence_transformers) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yexua\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.2.1)\n",
      "Installing collected packages: torchvision, sentence_transformers\n",
      "Successfully installed sentence_transformers-2.2.2 torchvision-0.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\yexua\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似度矩陣：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831008</td>\n",
       "      <td>0.704688</td>\n",
       "      <td>0.455559</td>\n",
       "      <td>0.447685</td>\n",
       "      <td>0.320219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663895</td>\n",
       "      <td>0.716362</td>\n",
       "      <td>0.260636</td>\n",
       "      <td>0.315838</td>\n",
       "      <td>0.164425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721420</td>\n",
       "      <td>0.434439</td>\n",
       "      <td>0.388585</td>\n",
       "      <td>0.321389</td>\n",
       "      <td>0.223621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.553203</td>\n",
       "      <td>0.432848</td>\n",
       "      <td>0.300483</td>\n",
       "      <td>0.328760</td>\n",
       "      <td>0.123623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.366995</td>\n",
       "      <td>0.383427</td>\n",
       "      <td>0.634148</td>\n",
       "      <td>0.372137</td>\n",
       "      <td>0.264406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  0.831008  0.704688  0.455559  0.447685  0.320219\n",
       "1  0.663895  0.716362  0.260636  0.315838  0.164425\n",
       "2  0.721420  0.434439  0.388585  0.321389  0.223621\n",
       "3  0.553203  0.432848  0.300483  0.328760  0.123623\n",
       "4  0.366995  0.383427  0.634148  0.372137  0.264406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標記：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>相似詞</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   相似詞\n",
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "還有許多重點尚未討論到，繼續加油喔!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 多个句子（关键词）\n",
    "keywords1 = \"太陽能、光電效應、太陽能板、能量轉換、環保\"\n",
    "keywords2 = \"太陽能發電、光能、地球暖化、熱、狗\"\n",
    "\n",
    "# 将关键词分割成单词列表\n",
    "keywords1_list = keywords1.split('、')\n",
    "keywords2_list = keywords2.split('、')\n",
    "\n",
    "# 加载预训练模型\n",
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "# 对关键词进行编码以获取嵌入向量\n",
    "embeddings1 = model.encode(keywords1_list, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(keywords2_list, convert_to_tensor=True)\n",
    "\n",
    "# 计算关键词之间的余弦相似度\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "# 创建DataFrame并添加相似度矩阵\n",
    "similarity_df = pd.DataFrame(cosine_scores.cpu().numpy())\n",
    "\n",
    "# 设置相似度阈值\n",
    "threshold = 0.7\n",
    "\n",
    "# 创建标志列\n",
    "flagged_series = similarity_df.apply(lambda x: 1 if (x > threshold).any() else 0)\n",
    "\n",
    "# 将标志列转换为DataFrame\n",
    "flagged_df = pd.DataFrame(flagged_series, columns=['相似詞'])\n",
    "\n",
    "# 打印相似度矩阵\n",
    "print(\"相似度矩陣：\")\n",
    "display(similarity_df)\n",
    "\n",
    "# 打印标志列\n",
    "print(\"標記：\")\n",
    "display(flagged_df)\n",
    "\n",
    "num_ones = flagged_series.sum()\n",
    "\n",
    "# 检查如果1的数量少于一半，输出\"不够深入\"\n",
    "if num_ones < len(flagged_series) / 2:\n",
    "    print(\"還有許多重點尚未探討到，繼續加油喔!\")\n",
    "elif num_ones < len(flagged_series) / 4:\n",
    "    print(\"討論內容有點偏題了，有什麼需要幫忙的嗎？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似度： 0.3808121979236603\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "# from scipy.spatial.distance import cosine\n",
    "\n",
    "# # 句子\n",
    "# sentences = ['太陽能', '光']\n",
    "\n",
    "# # 加载分词器和模型\n",
    "# tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "# model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# # Tokenize sentences\n",
    "# encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# # Compute token embeddings\n",
    "# with torch.no_grad():\n",
    "#     model_output = model(**encoded_input)\n",
    "\n",
    "# # Perform pooling\n",
    "# sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# # Normalize embeddings\n",
    "# sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "# print(\"Sentence embeddings:\")\n",
    "# print(sentence_embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
